- title: "Visual Haptic Reasoning: Estimating Contact Forces by Observing Deformable Object Interactions"
  authors: Yufei Wang, David Held, and Zackory Erickson
  year: 2022
  type: conference
  venue: IROS
  image: ../images/vhr.jpg
  id: wang2022visual
  projectpage: 
  code: 
  bibtex: |
      @inproceedings{wang2022visual,
          title={Visual Haptic Reasoning: Estimating Contact Forces by Observing Deformable Object Interactions},
          author={Wang, Yufei and Held, David and Erickson, Zackory},
          booktitle={2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
          year={2022},
          organization={IEEE}
      }
  abstract: "Robotic manipulation of highly deformable cloth presents a promising opportunity to assist people with several daily tasks, such as washing dishes; folding laundry; or dressing, bathing, and hygiene assistance for individuals with severe motor impairments. In this work, we introduce a formulation that enables a collaborative robot to perform visual haptic reasoning with cloth---the act of inferring the location and magnitude of applied forces during physical interaction. We present two distinct model representations, trained in physics simulation, that enable haptic reasoning using only visual and robot kinematic observations. We conducted quantitative evaluations of these models in simulation for robot-assisted dressing, bathing, and dish washing tasks, and demonstrate that the trained models can generalize across different tasks with varying interactions, human body sizes, and object shapes. We also present results with a real-world mobile manipulator, which used our simulation-trained models to estimate applied contact forces while performing physically assistive tasks with cloth. Videos can be found at our project webpage."
  awards: 
  video: 
  pdf: 

- title: "CapSense: A Real-Time Capacitive Sensor Simulation Framework for Physical Human-Robot Interaction"
  authors: Christian Sch√∂ffmann, Zackory Erickson, and Hubert Zangl
  year: 2022
  type: journal
  venue: IEEE Robotics and Automation Letters (RA-L)
  image: ../images/capsense.jpg
  id: schoffmann2022capsense
  projectpage: 
  code: https://github.com/chstetco/capsense
  bibtex: |
      @article{schoffmann2022capsense,
          author={Sch{\"o}ffmann, Christian and Erickson, Zackory and Zangl, Hubert},
          journal={IEEE Robotics and Automation Letters}, 
          title={CapSense: A Real-Time Capacitive Sensor Simulation Framework for Physical Human-Robot Interaction}, 
          year={2022}
      }
  abstract: "This article presents CapSense, a real-time open-source capacitive sensor simulation framework for robotic applications. CapSense provides raw data of capacitive proximity sensors based on a fast and efficient 3D finite-element method (FEM) implementation. The proposed framework is interfaced to off-the-shelf robot and physics simulation environments to couple dynamic interaction of the environment with an electro-static solver for capacitance computation in real-time. The FEM method proposed in this article relies on a static tetrahedral mesh of the sensor surrounding without a-posteriori re-meshing and achieves high update rates by an adaptive update step. CapSense is flexible due to various configuration parameters (i.e. number, size, shape and location of electrodes) and serves as a platform for investigation of capacitive sensors in robotic applications. By using the proposed framework, researchers can simulate capacitive sensors in different scenarios and investigate these sensors and their configuration prior to installation and fabrication of real hardware. The proposed framework opens new research opportunities via sim-to-real transfer of capacitive sensing. The simulation approach is validated by comparing real-world results of different scenarios with simulation results. In order to showcase the benefits of CapSense in physical Human-Robot Interaction (pHRI), the framework is evaluated in a robotic healthcare scenario."
  awards: 
  video: 
  pdf: https://ieeexplore.ieee.org/document/9833265

- title: "Characterizing Multidimensional Capacitive Servoing for Physical Human-Robot Interaction"
  authors: Zackory Erickson, Henry M. Clever, Vamsee Gangaram, Eliot Xing, Greg Turk, C. Karen Liu, and Charles C. Kemp
  year: 2022
  type: journal
  venue: IEEE Transactions on Robotics (T-RO)
  image: ../images/capservoing.jpg
  id: erickson2022characterizing
  projectpage: 
  code: 
  bibtex: |
      @article{erickson2022characterizing,
          title={Characterizing Multidimensional Capacitive Servoing for Physical Human-Robot Interaction},
          author={Erickson, Zackory and Clever, Henry M and Gangaram, Vamsee and Xing, Eliot and Turk, Greg and Liu, C Karen and Kemp, Charles C},
          journal={IEEE Transactions on Robotics (T-RO)},
          year={2022}
      }
  abstract: "Towards the goal of robots performing robust and intelligent physical interactions with people, it is crucial that robots are able to accurately sense the human body, follow trajectories around the body, and track human motion. This study introduces a capacitive servoing control scheme that allows a robot to sense and navigate around human limbs during close physical interactions. Capacitive servoing leverages temporal measurements from a multi-electrode capacitive sensor array mounted on a robot's end effector to estimate the relative position and orientation (pose) of a nearby human limb. Capacitive servoing then uses these human pose estimates from a data-driven pose estimator within a feedback control loop in order to maneuver the robot's end effector around the surface of a human limb. We provide a design overview of capacitive sensors for human-robot interaction and then investigate the performance and generalization of capacitive servoing through an experiment with 12 human participants. The results indicate that multidimensional capacitive servoing enables a robot's end effector to move proximally or distally along human limbs while adapting to human pose. Using a cross-validation experiment, results further show that capacitive servoing generalizes well across people with different body size."
  awards: 
  video: 
  pdf: https://arxiv.org/pdf/2105.11582.pdf

- title: "Bodies Uncovered: Learning to Manipulate Real Blankets Around People via Physics Simulations"
  authors: Kavya Puthuveetil, Charles C. Kemp, and Zackory Erickson
  year: 2022
  type: journal
  venue: IEEE Robotics and Automation Letters (RA-L)
  image: ../images/bodies_uncovered.jpg
  id: puthuveetil2022bodies
  projectpage: https://rchi-lab.github.io/bodies-uncovered/
  code: https://github.com/RCHI-Lab/bodies-uncovered
  bibtex: |
      @article{puthuveetil2022bodies,
          author={Puthuveetil, Kavya and Kemp, Charles C. and Erickson, Zackory},
          journal={IEEE Robotics and Automation Letters}, 
          title={Bodies Uncovered: Learning to Manipulate Real Blankets Around People via Physics Simulations}, 
          year={2022},
          volume={7},
          number={2},
          pages={1984-1991},
          doi={10.1109/LRA.2022.3142732}
      }
  abstract: "While robots present an opportunity to provide physical assistance to older adults and people with mobility impairments in bed, people frequently rest in bed with blankets that cover the majority of their body. To provide assistance for many daily self-care tasks, such as bathing, dressing, or ambulating, a caregiver must first uncover blankets from part of a person's body. In this work, we introduce a formulation for robotic bedding manipulation around people in which a robot uncovers a blanket from a target body part while ensuring the rest of the human body remains covered. We compare two approaches for optimizing policies which provide a robot with grasp and release points that uncover a target part of the body: 1) reinforcement learning and 2) self-supervised learning with optimization to generate training data. We trained and conducted evaluations of these policies in physics simulation environments that consist of a deformable cloth mesh covering a simulated human lying supine on a bed. In addition, we transfer simulation-trained policies to a real mobile manipulator and demonstrate that it can uncover a blanket from target body parts of a manikin lying in bed. Source code is available online."
  awards: 
  video: https://www.youtube.com/watch?v=oTO2NqfSAXw
  pdf: https://arxiv.org/pdf/2109.04930.pdf


# - title: "Characterizing Multidimensional Capacitive Servoing for Physical Human-Robot Interaction"
#   authors: Zackory Erickson, Henry M. Clever, Vamsee Gangaram, Eliot Xing, Greg Turk, C. Karen Liu, Charles C. Kemp
#   year: 2021
#   type: preprint
#   venue: arXiv preprint
#   image: ../images/assistive_gym.jpg
#   id: erickson2021characterizing
#   projectpage: 
#   code: 
#   bibtex: |
#       @article{erickson2021characterizing,
#           title={Characterizing Multidimensional Capacitive Servoing for Physical Human-Robot Interaction},
#           author={Erickson, Zackory and Clever, Henry M and Gangaram, Vamsee and Xing, Eliot and Turk, Greg and Liu, C Karen and Kemp, Charles C},
#           journal={arXiv preprint arXiv:2105.11582},
#           year={2021}
#       }
#   abstract: "Towards the goal of robots performing robust and intelligent physical interactions with people, it is crucial that robots are able to accurately sense the human body, follow trajectories around the body, and track human motion. This study introduces a capacitive servoing control scheme that allows a robot to sense and navigate around human limbs during close physical interactions. Capacitive servoing leverages temporal measurements from a multi-electrode capacitive sensor array mounted on a robot's end effector to estimate the relative position and orientation (pose) of a nearby human limb. Capacitive servoing then uses these human pose estimates from a data-driven pose estimator within a feedback control loop in order to maneuver the robot's end effector around the surface of a human limb. We provide a design overview of capacitive sensors for human-robot interaction and then investigate the performance and generalization of capacitive servoing through an experiment with 12 human participants. The results indicate that multidimensional capacitive servoing enables a robot's end effector to move proximally or distally along human limbs while adapting to human pose. Using a cross-validation experiment, results further show that capacitive servoing generalizes well across people with different body size."
#   awards: 
#   video: 
#   pdf: https://arxiv.org/pdf/2105.11582.pdf

# - title: "Assistive Gym: A Physics Simulation Framework for Assistive Robotics"
#   authors: Zackory Erickson, Vamsee Gangaram, Ariel Kapusta, C. Karen Liu, and Charles C. Kemp
#   year: 2020
#   type: conference
#   venue: IEEE International Conference on Robotics and Automation (ICRA)
#   image: ../images/assistive_gym.jpg
#   id: erickson2020assistive
#   projectpage:
#   code: https://github.com/Healthcare-Robotics/assistive-gym
#   bibtex: |
#       @inproceedings{erickson2020assistive,
#           title={Assistive gym: A physics simulation framework for assistive robotics},
#           author={Erickson, Zackory and Gangaram, Vamsee and Kapusta, Ariel and Liu, C Karen and Kemp, Charles C},
#           booktitle={2020 IEEE International Conference on Robotics and Automation (ICRA)},
#           pages={10169--10176},
#           year={2020},
#           organization={IEEE}
#       }
#   abstract: "Autonomous robots have the potential to serve as versatile caregivers that improve quality of life for millions of people worldwide. Yet, conducting research in this area presents numerous challenges, including the risks of physical interaction between people and robots. Physics simulations have been used to optimize and train robots for physical assistance, but have typically focused on a single task. In this paper, we present Assistive Gym, an open source physics simulation framework for assistive robots that models multiple tasks. It includes six simulated environments in which a robotic manipulator can attempt to assist a person with activities of daily living (ADLs): itch scratching, drinking, feeding, body manipulation, dressing, and bathing. Assistive Gym models a person's physical capabilities and preferences for assistance, which are used to provide a reward function. We present baseline policies trained using reinforcement learning for four different commercial robots in the six environments. We demonstrate that modeling human motion results in better assistance and we compare the performance of different robots. Overall, we show that Assistive Gym is a promising tool for assistive robotics research."
#   awards: 
#   video: https://www.youtube.com/watch?v=EFKqNKO3P60
#   pdf: https://arxiv.org/pdf/1910.04700.pdf
